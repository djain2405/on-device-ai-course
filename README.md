ğŸ“˜ **On-Device AI Course**

_The Open Guide to Building Intelligent Mobile Apps (iOS + Android)_
By Divya Jain

Welcome to the On-Device AI Course - a modular, hands-on curriculum designed to help mobile developers build fast, private, intelligent apps that run entirely on the device.

AI is no longer confined to the cloud.
Your iPhone and Android devices now have Neural Engines, NNAPI, GPU delegates, and optimized ML runtimes capable of running powerful models offline.

This course shows you how to use them - clearly, practically, and without overwhelm.

-------------------------------------------------------------------------------------------------------------

ğŸ¯ **Who This Course Is For**

* iOS developers curious about Core ML + on-device inference

* Android developers exploring TensorFlow Lite + NNAPI

* AI engineers who want to bring models onto mobile

* Product engineers building privacy-first intelligent features

* Anyone who wants to understand mobile AI end-to-end

* Each module is self-contained and beginner-friendly.

-------------------------------------------------------------------------------------------------------------

ğŸ§© **Course Modules**

Module 1 - Understanding On-Device AI (Foundations)

What on-device AI is, why itâ€™s exploding, architectures, hardware, and your first runnable demo.

ğŸ‘‰ ``` modules/01_introduction/ ```

Module 2 - TensorFlow Lite on Android

Hands-on project with TFLite, delegates, model formats, and a working classifier in Jetpack Compose.

ğŸ‘‰ ``` modules/02_android_tflite/ ```

Module 3 - Core ML on iOS

Build an on-device classifier with SwiftUI, MobileNetV2, confidence scoring, and animations.

ğŸ‘‰ ``` modules/03_ios_coreml/ ```

Module 4 - Privacy-Preserving AI Patterns

Edge inference, hybrid models, user safety design, offline fallbacks, and architecture patterns.

ğŸ‘‰ ``` modules/04_privacy_preserving_ai/ ```

Module 5 - Behavioral Intelligence on Mobile

Inspired by your HiRoad experience - motion patterns, contextual inference, and mobile sensing.

ğŸ‘‰ ``` modules/05_behavioral_intelligence/ ```

Module 6 - On-Device LLMs (Gemini Nano, LlamaEdge)

How small LLMs run locally, token limits, latency, and on-device summarization or classification.

ğŸ‘‰ ``` modules/06_gemini_nano_llms/ ```

Module 7 - Production-Ready AI

Battery, performance, model updates, feature flagging, OTA model delivery, testing strategies.

ğŸ‘‰ ``` modules/07_production_ready_ai/ ```

Module 8 - Capstone Project: Ship an On-Device AI Feature

Youâ€™ll build and publish your own mobile AI feature.

ğŸ‘‰ ``` modules/08_capstone/ ```

-------------------------------------------------------------------------------------------------------------

ğŸ§ª** What Youâ€™ll Build**

* iOS and Android on-device classifiers

* UX-enhanced AI experiences

* Privacy-by-design workflows

* Behavior-based inference models

* Lightweight on-device LLM demos

* A production-ready mobile AI pipeline

* A personal capstone project you can publish

-------------------------------------------------------------------------------------------------------------

**ğŸ›  Tech Used**

* iOS: Core ML, SwiftUI

* Android: TensorFlow Lite, NNAPI, Compose

* LLMs: Gemini Nano, LlamaEdge, TFLite-LLaMA

* Tools: Python, ONNX, MLKit, TFLite Converter

-------------------------------------------------------------------------------------------------------------

ğŸš€ How to Use This Course

Each module includes:

* âœï¸ Written lesson

* ğŸ§© Hands-on code

* ğŸ¥ Optional demo video

* ğŸ›  A â€œBuild Thisâ€ challenge

* ğŸ’¬ A discussion thread (GitHub issues)

You can start from Module 1 or jump directly to any module.

-------------------------------------------------------------------------------------------------------------

â¤ï¸ Contributions

This is an open course.
If youâ€™d like to add:

* modules

* improvements

* demos

* translations

please open an issue or pull request.

